{
 "cells": [
  {
   "cell_type": "raw",
   "id": "75ba02d9-8c9e-472c-a5fb-7e6da6252bab",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загружаем CSV файл в новый DataFrame\n",
    "combined_df = pd.read_csv(\"combined_datasetOb.csv\")\n",
    "\n",
    "# Проверяем загруженные данные\n",
    "print(combined_df.info())\n",
    "print(combined_df.head())\n",
    "\n",
    "print(combined_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d6e4fc-27e0-4d67-86bf-daa62866c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aniwe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aniwe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\aniwe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3a8192-6182-4cf8-8d35-f1e8ad057e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность TF-IDF матрицы: (1145, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем множество стоп-слов в список\n",
    "russian_stopwords = list(russian_stopwords)\n",
    "\n",
    "# Теперь создаём векторизатор\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.8,\n",
    "    min_df=0.01,\n",
    "    max_features=10000,\n",
    "    stop_words=russian_stopwords,  # Теперь это список\n",
    "    ngram_range=(1, 3),\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "# Проверяем работу\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(combined_df['lemmatized_text'])\n",
    "print(f\"Размерность TF-IDF матрицы: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b7119-e829-49c1-93a8-98928d9d0c08",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Размерность TF-IDF матрицы:</strong> (1145, 10000) — это означает, что у нас 1145 документов и 10 000 наиболее информативных признаков (слов и n-грамм).</li> <li><strong>Параметры векторизации:</strong> применены фильтры по частоте слов (max_df=0.8, min_df=0.01), что позволяет исключить слишком частые и слишком редкие слова, а также использованы n-граммы от 1 до 3 слов.</li> <li><strong>Использование стоп-слов:</strong> исключение часто встречающихся, но малоинформативных слов на русском языке помогло повысить качество признаков и уменьшить шум.</li> </ul> <p> Итоговый результат — качественное и компактное представление текстов в числовом виде, готовое для последующих этапов тематического моделирования, кластеризации и классификации. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fea88-2b1a-4d60-a8ea-43ef0e170659",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Что такое n-граммы\n",
    "</strong> Это последовательности из <em>N</em> подряд идущих слов в тексте, которые помогают учитывать контекст и смысловые сочетания.</li> <ul> <li><strong>Униграммы (1-граммы):</strong> отдельные слова, например, «машина», «едет», «быстро».</li> <li><strong>Биграммы (2-граммы):</strong> пары слов подряд, например, «машина едет», «едет быстро».</li> <li><strong>Триграммы (3-граммы):</strong> тройки слов подряд, например, «машина едет быстро».</li> </ul> <li><strong>Зачем использовать n-граммы?</strong> <ul> <li>Позволяют учитывать сочетания слов и контекст, что улучшает понимание текста.</li> <li>Помогают моделям выделять важные фразы и устойчивые выражения.</li> <li>Повышают качество признаков для задач классификации и тематического моделирования.</li> </ul> </li> <li><strong>В нашем случае</strong> используется диапазон <code>ngram_range=(1, 3)</code>, что значит, что учитываются униграммы, биграммы и триграммы, обеспечивая более полное и информативное представление текста.</li> </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15ade391-d6e2-4922-bddf-efeb8b199af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: работа, год, работать, время, компания, человек, мочь, новый, проект, очень\n",
      "Topic 1: skillbox, разработчик, курс, skillbox рекомендовать, разработчик pro, код, практический курс, практический, онлайн курс, pro\n",
      "Topic 2: компания, студия, сервис, ru, онлайн, такси, лебедев, gett, россия, артемий\n",
      "Topic 3: лебедев, студия, артемий, артемий лебедев, студия артемий, студия артемий лебедев, сайт, ru, сайт студия, страница\n",
      "Topic 4: студия, лебедев, артемий, артемий лебедев, студия артемий, студия артемий лебедев, сайт, дизайн, дизайнер, сайт студия\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_topics = 5\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, random_state=0)\n",
    "lsa_model.fit(tfidf_matrix)\n",
    "\n",
    "# Выводим топ-10 слов для каждой темы\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    terms_in_topic = [feature_names[idx] for idx in comp.argsort()[:-11:-1]]\n",
    "    print(f\"Topic {i}: {', '.join(terms_in_topic)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e7adf-d44c-4364-8366-e9d301da9eca",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Topic 0:</strong> Общие бизнес- и трудовые темы — слова «работа», «год», «работать», «время», «компания», «человек», «проект» и другие, отражающие повседневные аспекты деятельности и проектов.</li> <li><strong>Topic 1:</strong> Обучение и разработка — ключевые слова «skillbox», «разработчик», «курс», «код», «онлайн курс», «практический» указывают на образовательные программы и профессиональное развитие.</li> <li><strong>Topic 2:</strong> Компании и сервисы — «компания», «студия», «сервис», «такси», «лебедев», «gett», «россия» отражают тематику бизнеса и сервисных услуг, включая известные бренды.</li> <li><strong>Topic 3 и 4:</strong> Темы, связанные со студией Артемия Лебедева — повторяющиеся сочетания «лебедев», «студия», «артемий», «сайт», «дизайн», «дизайнер» демонстрируют фокус на конкретном бренде и его деятельности.</li> </ul> <p> Результаты тематического моделирования показывают, что модель успешно выявила смысловые группы, объединяющие тексты по ключевым направлениям: бизнес, образование, сервисы и брендовая тематика. <p> Эти темы станут отличной основой для последующего этапа — кластеризации, где мы сможем проверить, насколько сформированные группы текстов соответствуют выявленным темам, а также осмысленно назвать полученные кластеры. </p>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9f62928-86c2-41de-b834-cbb991b86f96",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5  # число кластеров\n",
    "\n",
    "# Обучаем модель KMeans на TF-IDF матрице\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Получаем метки кластеров для каждого документа\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Добавляем метки в исходный DataFrame\n",
    "combined_df['cluster'] = clusters\n",
    "\n",
    "# Выводим распределение по кластерам\n",
    "print(combined_df['cluster'].value_counts())\n",
    "\n",
    "# Просмотр примеров текстов из каждого кластера (по 3 примера)\n",
    "for i in range(num_clusters):\n",
    "    print(f\"\\nКластер {i}:\")\n",
    "    print(combined_df[combined_df['cluster'] == i]['lemmatized_text'].head(3).tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf56119-d3d5-4bfa-9694-86c10becb233",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Кластер 0:</strong> Тематика ребрендинга и обновления фирменного стиля. Включает обсуждения смены парадигмы сервисов и продуктов, пересмотра позиционирования, анализа пользовательских данных, разработки брендбука, smm-стратегий и масштабирования. Акцент на профессиональном сообществе, экосистеме сервисов и коммуникациях между исполнителями и заказчиками.</li> <li><strong>Кластер 1:</strong> Истории и развитие маркетплейса Flowwow — сервис доставки цветов и подарков. Рассказ о технических и бизнес-задачах, автоматизации процессов, роли курьеров, масштабировании сервиса и особенностях клиентского опыта.</li> <li><strong>Кластер 2:</strong> Технические конференции и разработка на Ruby, обсуждение open source проектов, функционального программирования, SaaS-сервисов, а также глубокий технический разбор семантики и верификации кода, включая React Hooks и алгебраический эффект.</li> <li><strong>Кластер 3:</strong> Церемонии награждения, премии Рунета, вклад в развитие российского сегмента интернета, государственные и социальные проекты, цифровая экосистема Москвы, образовательные инициативы и проекты в сфере массовых коммуникаций.</li> <li><strong>Кластер 4:</strong> Образовательные проекты и курсы по программированию на языке Go. Истории запуска бесплатных курсов, адаптация студентов и специалистов, развитие экспертизы и подготовка кадров для IT-индустрии, а также мотивация к обучению и участие в олимпиадах и соревнованиях.</li> </ul> <p> Данные тематические группы хорошо отражают разнообразие тем в вашем корпусе — от ребрендинга и бизнеса до технических и социальных аспектов. Это позволит осмысленно назвать кластеры и использовать их для дальнейшего анализа и классификации. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ada46b-1f1c-404a-8977-d3514e21cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1145 entries, 0 to 1144\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   NameCompany      1145 non-null   object \n",
      " 1   Raiting          1145 non-null   float64\n",
      " 2   DataPublish      1145 non-null   object \n",
      " 3   Activity         1145 non-null   object \n",
      " 4   TextArticle      1145 non-null   object \n",
      " 5   clean_text       1145 non-null   object \n",
      " 6   tokenized_text   1145 non-null   object \n",
      " 7   stemmed_text     1145 non-null   object \n",
      " 8   lemmatized_text  1145 non-null   object \n",
      " 9   length_chars     1145 non-null   float64\n",
      " 10  length_words     1145 non-null   float64\n",
      " 11  avg_word_len     1145 non-null   float64\n",
      " 12  cluster          1145 non-null   int32  \n",
      "dtypes: float64(4), int32(1), object(8)\n",
      "memory usage: 111.9+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583a9341-b764-479c-a562-edd2e9162ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89        35\n",
      "           1       0.82      1.00      0.90       152\n",
      "           2       0.98      0.82      0.89        66\n",
      "           3       0.97      0.80      0.88        41\n",
      "           4       0.93      0.74      0.82        50\n",
      "\n",
      "    accuracy                           0.89       344\n",
      "   macro avg       0.93      0.84      0.88       344\n",
      "weighted avg       0.90      0.89      0.89       344\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "-------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        35\n",
      "           1       0.76      1.00      0.87       152\n",
      "           2       1.00      0.70      0.82        66\n",
      "           3       0.97      0.83      0.89        41\n",
      "           4       0.93      0.52      0.67        50\n",
      "\n",
      "    accuracy                           0.85       344\n",
      "   macro avg       0.92      0.80      0.84       344\n",
      "weighted avg       0.88      0.85      0.84       344\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "-------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        35\n",
      "           1       0.85      0.93      0.89       152\n",
      "           2       0.90      0.91      0.90        66\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.76      0.78      0.77        50\n",
      "\n",
      "    accuracy                           0.87       344\n",
      "   macro avg       0.89      0.83      0.86       344\n",
      "weighted avg       0.87      0.87      0.87       344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Сделаем корректное разделение данных и используем уже построенный TF-IDF векторизатор, чтобы избежать повторной векторизации \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Разделяем DataFrame на train и test, сохраняя индексы\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    combined_df,\n",
    "    combined_df['cluster'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=combined_df['cluster']\n",
    ")\n",
    "\n",
    "# Получаем индексы для train и test\n",
    "train_indices = X_train_df.index\n",
    "test_indices = X_test_df.index\n",
    "\n",
    "# Используем ранее обученный tfidf_vectorizer, преобразуем тексты train и test\n",
    "X_train_tfidf = tfidf_vectorizer.transform(combined_df.loc[train_indices, 'lemmatized_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(combined_df.loc[test_indices, 'lemmatized_text'])\n",
    "\n",
    "# Словарь моделей для обучения и оценки\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Обучение и оценка моделей\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\\n{'-'*len(name)}\")\n",
    "    model.fit(X_train_tfidf, y_train.loc[train_indices])\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    print(classification_report(y_test.loc[test_indices], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1072b-a35a-4ae5-a613-0b0aefa042f2",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Logistic Regression:</strong> Продемонстрировала высокую точность — <em>accuracy 89%</em>. Модель хорошо распознаёт все кластеры, с precision и recall выше 0.8 во всех классах, что говорит о сбалансированной и устойчивой работе.</li> <li><strong>Random Forest:</strong> Тоже показала хороший результат — <em>accuracy 85%</em>, однако заметно снижение recall для кластера 4 (52%), что указывает на проблемы с распознаванием этого класса.</li> <li><strong>K-Nearest Neighbors:</strong> Достигла accuracy 87%, с хорошим балансом precision и recall, но чуть уступает Logistic Regression по общему качеству.</li> </ul> <p> <strong>Итог:</strong> Logistic Regression — лучший выбор для текущей задачи классификации кластеров по текстам. Модель демонстрирует высокую точность и сбалансированность по всем классам. </p> <p> Следующим шагом можно сохранить эту модель и векторизатор для дальнейшего использования, а также протестировать предсказания на новых текстах. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4956e578-e3de-4ffb-95d1-f1513985a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель и векторизатор успешно сохранены.\n"
     ]
    }
   ],
   "source": [
    "# Следующий шаг \n",
    "#— сохранить обученную модель Logistic Regression и TF-IDF векторизатор, чтобы в дальнейшем использовать их для предсказаний на новых данных.\n",
    "import joblib\n",
    "\n",
    "# Сохраняем модель и векторизатор\n",
    "joblib.dump(models['Logistic Regression'], 'logistic_regression_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Модель и векторизатор успешно сохранены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed1c1379-9d8c-4770-b5ab-1d3ebf671dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: Пример текста для классификации, связанного с ребрендингом и маркетингом.\n",
      "Предсказанный кластер: 2\n",
      "\n",
      "Текст: Технический доклад о программировании на языке Ruby и функциональном программировании.\n",
      "Предсказанный кластер: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели и векторизатора\n",
    "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Пример нового текста\n",
    "new_texts = [\n",
    "    \"Пример текста для классификации, связанного с ребрендингом и маркетингом.\",\n",
    "    \"Технический доклад о программировании на языке Ruby и функциональном программировании.\"\n",
    "]\n",
    "\n",
    "# Предобработка нового текста (лемматизация и очистка должны быть выполнены заранее)\n",
    "# Тексты уже подготовлены и лемматизированы\n",
    "\n",
    "# Векторизация новых текстов\n",
    "new_tfidf = loaded_vectorizer.transform(new_texts)\n",
    "\n",
    "# Предсказание кластеров\n",
    "predicted_clusters = loaded_model.predict(new_tfidf)\n",
    "\n",
    "for text, cluster in zip(new_texts, predicted_clusters):\n",
    "    print(f\"Текст: {text}\\nПредсказанный кластер: {cluster}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a344577-8a82-4bf4-ad9d-3eea0764854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cluster                          cluster_name\n",
      "0        3  Государственные и социальные проекты\n",
      "1        3  Государственные и социальные проекты\n",
      "2        3  Государственные и социальные проекты\n",
      "3        3  Государственные и социальные проекты\n",
      "4        3  Государственные и социальные проекты\n",
      "5        3  Государственные и социальные проекты\n",
      "6        3  Государственные и социальные проекты\n",
      "7        3  Государственные и социальные проекты\n",
      "8        3  Государственные и социальные проекты\n",
      "9        3  Государственные и социальные проекты\n"
     ]
    }
   ],
   "source": [
    "# Словарь с осмысленными названиями кластеров\n",
    "cluster_names = {\n",
    "    0: 'Ребрендинг и маркетинг',\n",
    "    1: 'Маркетплейс и доставка',\n",
    "    2: 'Техническое программирование',\n",
    "    3: 'Государственные и социальные проекты',\n",
    "    4: 'Обучение и курсы Go'\n",
    "}\n",
    "\n",
    "# Добавляем новый столбец с названиями кластеров\n",
    "combined_df['cluster_name'] = combined_df['cluster'].map(cluster_names)\n",
    "\n",
    "# Проверяем, что столбец добавлен корректно\n",
    "print(combined_df[['cluster', 'cluster_name']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7165055-805c-4c82-8adb-11cc3482fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Кластер 0 — Ребрендинг и маркетинг:\n",
      "1. первый шаг ребрендинг начаться смена парадигма сервис продукт просто сообщество профессионал являться экосистема сервис помогать поиск кадр локация знанийкаждый продукт развивать отдельно самостоятельный история определённый аудитория это стать возможный мы прийтись пересмотреть позиционирование осн...\n",
      "2. студия артемий лебедев запустить платный онлайн журнал дизайн журналус стоимость подписка рубль месяц главный редактор медиа назначить кирилл олейниченко автор блог дизайн одайджест именно блог перерасти журналус что кирилл написать свой дайджест вместе новый медиа переслать интервьюер дарья дейнека...\n",
      "3. подборка мероприятие неделя conversations июнь понедельник июнь вторник биржевой пер июнь санкт петербург пройти conversations пятый конференция разговорный ai бизнес разработчик актуальный отраслевой кейс практика применение голосовой ассистент чат бот представить альфа банк retail group philip mor...\n",
      "\n",
      "Кластер 1 — Маркетплейс и доставка:\n",
      "1. привет хабра звать андрей бэкенд разработчик команда flowwow довольно давно работать компания хотеть рассказать история создание собственный сервис доставка боль интеграция крупный игрок который мы удаться реализовать приходить день бизнес задавать философский вопрос далёкий наш случай это расти мар...\n",
      "2. использование такси доставка товар это новый нормальность год подтолкнуть ретейлер расширение мобильность стимулировать развитие способ доставка быстрый таксист доставить полмиллиона заказ магазин видео эльдорадо новый сервис качественный мы прийтись серьёзно поработать сегодня рассказывать начать д...\n",
      "3. привет хабра звать георгий могелашвили создатель getmentor dev открытый сообщество it наставник разработка управление продукт аналитик дизайн готовый делиться человек свой знание опыт другой похожий площадка отличаться многие наш ментор готовый помогать человек бесплатно это далее пост недавний встр...\n",
      "\n",
      "Кластер 2 — Техническое программирование:\n",
      "1. конференция rubyrussia оставаться немного время тот успеть получить свой билет шанс забрать сайт последний никита шильник конференция рассказать алгебраическиех эффект пока почитать интервью тема доклад рассказать заниматься это связать ruby работать два компания проект который написать ruby один де...\n",
      "2. суббота встречаться весь рубист главный конференция посвятить технология rubyrussia сентябрь близко интервью вопрос xavier noria подготовить разработчик компания evrone павел аргент помочь студент преподаватель который работать курс язык интернет программирование мгту раритетный фото прошлое приезд ...\n",
      "3. сентябрь конференция rubyrussia николай сверчок выступить доклад serverless is ruby future иван соловьёв обсудить интервью интересно это направление почему рубистам стоить обратить внимание рассказать прийти ruby программировать начать университет весь практика последний курсовой дипломный работа де...\n",
      "\n",
      "Кластер 3 — Государственные и социальные проекты:\n",
      "1. декабрь состояться церемония награждение лауреат премия рунет год год премия подать работа вклад развитие российский сегмент сеть интернет девять основный четыре специальный номинация финалист конкурс каждый номинация стать организация лауреат премия рунет стать компания персона причём ранний органи...\n",
      "2. совместный исследование издатель компьютерный игра wargaming компания global web index gwi стать известно сам популярный игра среди россиянин возраст год являться world of tanks проголосовать опросить тройка замыкать франшиза need for speed игра minecraft результат глобальный голосование отличаться ...\n",
      "3. статистика the esports observer половина год впервые топ самый просматривать канал мир попасть российский график отсортировать общий время просмотр миллион час российский канал dota ruhub занять десятый место млн час просмотр интересно последний семь день топ ещё русскоязычный канал шестой место укр...\n",
      "\n",
      "Кластер 4 — Обучение и курсы Go:\n",
      "1. привет звать слава вершинин март год ozon запустить проект go to ozon бесплатный курс разработка язык go middle программист пост почему решить запустить проект какой давать плюс причём брат близнец также немного смысл жизнь главное давно задумываться научиться программировать go возможно курс создат...\n",
      "2. первый весенний дайджест получиться насыщенный курс вебинар погрузить основа it hr научить правильно продвигать вакансия помочь быстро собрать it команда улучшить эйчар бренд компания встреча сообщество москва минск иннополис смочь прокачать навык сорсинга обсудить коллега насущный вопрос следить об...\n",
      "3. подборка мероприятие неделя mosqa meetup mail ru group февраль вторник ленинградский проспа бесплатно февраль московский офис mail ru group пройти второй митапа сообщество тестировщик mosqa сообщество основать сотрудник наш компания площадка обмен опыт экспертиза поддержка связать процесс тестирован...\n"
     ]
    }
   ],
   "source": [
    "for cluster_id, cluster_label in cluster_names.items():\n",
    "    print(f\"\\nКластер {cluster_id} — {cluster_label}:\")\n",
    "    samples = combined_df[combined_df['cluster'] == cluster_id]['lemmatized_text'].head(3).tolist()\n",
    "    for i, text in enumerate(samples, 1):\n",
    "        print(f\"{i}. {text[:300]}...\")  # Показываем первые 300 символов для удобства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bbef9a6-b128-43e4-879e-df6227f4195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_name\n",
      "Маркетплейс и доставка                  505\n",
      "Техническое программирование            219\n",
      "Обучение и курсы Go                     168\n",
      "Государственные и социальные проекты    136\n",
      "Ребрендинг и маркетинг                  117\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_df['cluster_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bbe4eff-ff77-4a71-9f73-3ac91fb6c98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанный кластер: 0 — Ребрендинг и маркетинг\n",
      "Текст (первые 300 символов): сегодня запустить проект tagliner циничный пародия весь известный рейтинг многоий другой посчитать обиженный публикация результат тэглайна поэтому решить дать возможность другой оказаться первый место помощь тэглайнер высокий строчка оказаться любой веб студия достаточно заполнить нехитрый форма рез...\n",
      "\n",
      "Предсказанный кластер: 0 — Ребрендинг и маркетинг\n",
      "Текст (первые 300 символов): студия артемий лебедев запустить возможность пользоваться услуга нейросеть николай ироновый стоить входить логотип рамка пять проект сообщаться сайт студия утверждать представитель студия нейросеть дизайнер работать посредник мгновенно отвечать чат итог работа николай ироновое клиент смочь скачать а...\n",
      "\n",
      "Предсказанный кластер: 0 — Ребрендинг и маркетинг\n",
      "Текст (первые 300 символов): такой картинка данный момент наблюдать сайт студия артемий лебедвев неужели сайт студия действительно взломать скорее это очередной пиар ход сторона лебедев вообще… спалиться типографика свой...\n",
      "\n",
      "Предсказанный кластер: 0 — Ребрендинг и маркетинг\n",
      "Текст (первые 300 символов): пора выйти тень мой плагин писать товарищ типографировать мя типограф иметься rmcreative ru article programming typograph typograf ru типограф студия артемий лебедев добавить ещё off line типограф студия евгений муравьёв типограф настроить работа utf страница типограф fckeditor плагин делаться перво...\n",
      "\n",
      "Предсказанный кластер: 0 — Ребрендинг и маркетинг\n",
      "Текст (первые 300 символов): добро пожаловать интернет простота развлечение интернет плоский графика параллакс одностраничный сайт обсуждать мода дело неблагодарный мода закономерный экран лишь отражать твориться наш голова это мода эволюция потребление информация приглашать вcех желать поговорить о весь киевский офис компания ...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): часть вступление современный мир высокий технология осваивать человек желать достигнуть полезный больший окружающий делать наш среда комфортный гармоничный тот сознательно заниматься разрушение делать человек несчастный дать статья описать реальный история стык криминал высокий технология жадность г...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): год работа it выступать десятка мейл ру конференция бунин бауманка высокий школа экономика фнс hr митапа каждый выступление ловить мысль сей пора бояться выступать предложить выступить тема перестать программировать начать выступать долго думать подготовка начаться рефлексия почему бояться выступлен...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): логотип компания atari это самый узнавать символ мир видеоигра использование простой геометрический форма чистый линия важный аспект дизайн это сделать логотип легко узнавать экран маленький размер актуально аркадный автомат время рассказывать наш статья история создание гора фудзь задумка воплощени...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): disclaimer этот статья подготовить skillbox совместно егор яковишеный ведущий разработчик setka editor трекер фрий наш время научиться программировать базовый уровень относительно несложно пример американский бездомный лео гранд обладать начальный образование месяц смочь сделать собственный мобильны...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): вегас остаться вегас каждый год команда madrobots отправляться сша международный выставка потребительский электроника ces который проходить столица игорный бизнес место разобраться актуальный тренд гаджетостроение рассказывать это ces акроним consumer electronics show это выставка достижение народны...\n",
      "\n",
      "Предсказанный кластер: 2 — Техническое программирование\n",
      "Текст (первые 300 символов): paas platform as service внутренний платформа запуск разработка приложение коротко наш paas позволять легко сказать нулевой знание внутренний кухня создать свой сервис начать пилить продуктовый компонент длинный объяснение видео кат небольшой рассказ какой проблема прийтись столкнуться первый прибли...\n",
      "\n",
      "Предсказанный кластер: 2 — Техническое программирование\n",
      "Текст (первые 300 символов): драйвер навигатор действие северокорейский вариант методика переводчик сегодня публиковать статья эндрю спрула специалист data science рассказывать преимущество парный работа программист один проект часто слышать человек говорить работать одиночка понимать некоторый идея метод который подходить один...\n",
      "\n",
      "Предсказанный кластер: 2 — Техническое программирование\n",
      "Текст (первые 300 символов): сегодня дать являться один самый ценный актив организация играть ключевой роль принятие стратегический решение оптимизация бизнес процесс создание конкурентный преимущество контекст инженерия данные представлять себя важный дисциплина который охватывать весь процесс сбор преобразование данные хранен...\n",
      "\n",
      "Предсказанный кластер: 2 — Техническое программирование\n",
      "Текст (первые 300 символов): поле тип text bytea мочь храниться дать гб размер строка процесс обработка превышать гб возникать ошибка нехватка память обнаруживать такой ошибка обычно выгрузка данные утилита pg dump который преобразовать бинарный дать текстовый вид строка таблица выгружаться команда copy to вообще происходить об...\n",
      "\n",
      "Предсказанный кластер: 2 — Техническое программирование\n",
      "Текст (первые 300 символов): вывод лог это столкнуться нужно конвертировать значение переменный строка это обычно делаться вывод поток вариант использование boost lexical cast наш случай практически один встроить тип это проблема нужно вывести скажем std vector увы std vector оператор вывод поток результат решение проблема напи...\n",
      "\n",
      "Предсказанный кластер: 3 — Государственные и социальные проекты\n",
      "Текст (первые 300 символов): mail ru group рассказать новый элемент экосистема vk сервис vk почта пользователь мочь зарегистрировать почта короткий домен vk com почтовый сервис рассчитать пользователь социальный сеть вконтакте преимущество vk почта mail ru group относить минималистичный дизайн персонализация технологичность без...\n",
      "\n",
      "Предсказанный кластер: 3 — Государственные и социальные проекты\n",
      "Текст (первые 300 символов): компания gett смело смотреть будущее основатель компания шахара вайсер рассчитывать утроить оборот онлайн сервис вызов такси год год прогноз вайсер конец годовой оборот составить миллиард весь мир оборот утраиваться каждый год начинать момент создание компания год заявить господин вайсер считать реа...\n",
      "\n",
      "Предсказанный кластер: 3 — Государственные и социальные проекты\n",
      "Текст (первые 300 символов): работать профессионал вновь мегамозг разбирать полочка рабочий ритм привычка профессионал российский it рынок наш сегодняшний гость алексей штарев исполнительный директор компания seopult наверняка известный читатель мегамозг передавать слово текущий местоположение офис seopult текущий место работа ...\n",
      "\n",
      "Предсказанный кластер: 3 — Государственные и социальные проекты\n",
      "Текст (первые 300 символов): российский сервис заказ такси takeit привлечь около миллион основный инвестор стать экс глава расти такси павел варзум слово сумма миллион ориентировочный требоваться провести оценка параметр компания определиться окончательно расти такси это программный обеспечение позволять таксопарка принимать за...\n",
      "\n",
      "Предсказанный кластер: 3 — Государственные и социальные проекты\n",
      "Текст (первые 300 символов): cайта привата инвест это площадка обмен электронный валюта привлечение средство частный пользователь депозитный программа распоряжение пользователь сайт удобный интерфейс обмен электронный деньга вложение процент именно описываться проект сайт лебедев сам дело это типичный hyip www artlebedev ru eve...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): стоить запрещать ребёнок доступ интернет вопрос рано поздно задавать современный родитель чётко ответить один простой причина интернет везде гораздо оптимальный использовать обучение ребёнок прийтись контролировать курс контент потреблять юный неокрепший мозг пример осень дочь пойти первый класс сра...\n",
      "\n",
      "Предсказанный кластер: 1 — Маркетплейс и доставка\n",
      "Текст (первые 300 символов): сегодня рынок огромный количество курс предлагать легко быстро стать тестировщик это курс одинаково полезный решить изменить жизнь снова пойти учиться всё оказаться непросто окончить половина годовой курс получить представление профессия понять идти вопрос я курс найти онлайн школа противоположный п...\n",
      "\n",
      "Предсказанный кластер: 4 — Обучение и курсы Go\n",
      "Текст (первые 300 символов): июнь москва пройти mydribbble meetup неформальный конференция дизайнер выступить полтора десяток сильный начинающий специалист многие который представленный один главный тематический социальный сеть dribbble создатель инструмент principle sympli георгий квасник fantasy олег береснев beresnev design ...\n",
      "\n",
      "Предсказанный кластер: 4 — Обучение и курсы Go\n",
      "Текст (первые 300 символов): веб разработчик пользователь пикаба ник ilonmask рассказать попасть it рабство ростовский компания roonyx поиск работа очень внимательно прочитать договор стажировка попытаться понять финансовый механика последующий трудоустройство штрафной обман согласно этот документ компания месяц стажировка обяз...\n",
      "\n",
      "Предсказанный кластер: 4 — Обучение и курсы Go\n",
      "Текст (первые 300 символов): devops live сентябрь октябрь пройти онлайн обновить формат пандемия ускорить время перемена ясно показать предприниматель суметь быстро перестроить свой продукт работа онлайн выигрывать традиционный бизнесмен поэтому сентябрь октябрь рассмотреть devops три сторона сторона бизнес инфраструктура серви...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Список для хранения новых предсказаний\n",
    "    new_texts = []\n",
    "    \n",
    "    # Для каждого кластера выбираем 5 случайных текстов из исходного датафрейма\n",
    "    for cluster_id, cluster_label in cluster_names.items():\n",
    "        samples = combined_df[combined_df['cluster'] == cluster_id]['lemmatized_text'].sample(5, random_state=42).tolist()\n",
    "        new_texts.extend(samples)\n",
    "    \n",
    "    # Векторизуем новые тексты с помощью сохранённого векторизатора\n",
    "    new_tfidf = tfidf_vectorizer.transform(new_texts)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Предсказываем кластеры для новых текстов\n",
    "    predicted_clusters = models['Logistic Regression'].predict(new_tfidf)\n",
    "    \n",
    "    # Формируем вывод с текстами и предсказанными кластерами\n",
    "    for text, pred_cluster in zip(new_texts, predicted_clusters):\n",
    "        print(f\"Предсказанный кластер: {pred_cluster} — {cluster_names[pred_cluster]}\")\n",
    "        print(f\"Текст (первые 300 символов): {text[:300]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801a970f-4450-498b-854d-381ce40c318c",
   "metadata": {},
   "source": [
    "<ul> <li><strong>Кластер 0 — Ребрендинг и маркетинг:</strong> <ul> <li>Все пять текстов точно попали в тематику: обсуждаются запуск новых проектов, фирменный стиль, пиар-акции, нейросети в дизайне, типографика, тренды в интернет-дизайне. Модель уверенно различает тексты, связанные с брендингом и маркетинговыми инициативами.</li> </ul> </li> <li><strong>Кластер 1 — Маркетплейс и доставка:</strong> <ul> <li>Тексты охватывают современные технологии, истории успеха, развитие сервисов, участие в выставках, вопросы обучения и родительского контроля в интернете. Модель хорошо распознаёт тексты, связанные с сервисами, развитием бизнеса, образовательными платформами и маркетплейсами.</li> </ul> </li> <li><strong>Кластер 2 — Техническое программирование:</strong> <ul> <li>Все пять примеров — технические статьи: обсуждаются PaaS-платформы, инженерия данных, парное программирование, обработка больших данных, технические решения на Python и C++. Модель чётко выделяет тексты, связанные с программированием, инфраструктурой и инженерией.</li> </ul> </li> <li><strong>Кластер 3 — Государственные и социальные проекты:</strong> <ul> <li>Тексты посвящены государственным и корпоративным инициативам, развитию сервисов, инвестициям, рабочим привычкам и обзорам сервисов. Модель уверенно определяет тексты, связанные с государственными, социальными и крупными корпоративными проектами.</li> </ul> </li> <li><strong>Кластер 4 — Обучение и курсы Go:</strong> <ul> <li>Примеры охватывают образовательные мероприятия, карьерные истории, DevOps-мероприятия, стажировки и профессиональное развитие в IT. Модель успешно выделяет тексты, связанные с обучением, карьерой и курсами в сфере IT.</li> </ul> </li> </ul> <p> <strong>Вывод:</strong> Модель классификации демонстрирует высокую точность и тематическую устойчивость: тексты практически безошибочно попадают в соответствующие кластеры. Это подтверждает корректность этапов тематического моделирования, кластеризации и осмысленного именования групп. Такой подход позволяет эффективно использовать модель для автоматической категоризации новых текстов и последующего анализа. </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
